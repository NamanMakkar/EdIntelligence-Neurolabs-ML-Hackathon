{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EdIntelligence-NeuroLabs-Hackathon-Challenge-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jD7Lp2-16tX"
      },
      "source": [
        "# install dependencies: \r\n",
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3w6qITN2TLX"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\r\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xowP-PqK2WT1"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35oVrJSL2p-4"
      },
      "source": [
        "# Some basic setup:\r\n",
        "# Setup detectron2 logger\r\n",
        "import detectron2\r\n",
        "from detectron2.utils.logger import setup_logger\r\n",
        "setup_logger()\r\n",
        "\r\n",
        "# import some common libraries\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import imgaug as ia\r\n",
        "ia.seed(1)\r\n",
        "from imgaug import augmenters as iaa \r\n",
        "import imageio\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from pathlib import Path\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "# import some common detectron2 utilities\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.config import get_cfg\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader \r\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlc3v42Z2u6t"
      },
      "source": [
        "import pandas as pd\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPHcva0P2vie"
      },
      "source": [
        "images_dir = Path(\"drive/MyDrive/Hackathon-Challenge-1-Train/\")\r\n",
        "annotations_csv_f = Path(\"drive/MyDrive/train-challenge-2-first-attempt.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNZnDo3H3KeW"
      },
      "source": [
        "from detectron2.structures import BoxMode\r\n",
        "\r\n",
        "class Annotations:\r\n",
        "  def __init__(self):\r\n",
        "    self.annotations = None\r\n",
        "    self.categories = None\r\n",
        "    self.categories_map_reverse = None\r\n",
        "\r\n",
        "  def compute(self):\r\n",
        "    if self.annotations != None:\r\n",
        "      return self.annotations\r\n",
        "\r\n",
        "    # first read all the information\r\n",
        "    csv_data = {}\r\n",
        "    with annotations_csv_f.open() as f:\r\n",
        "      for line in f:\r\n",
        "        image_name, xmin, ymin, xmax, ymax, label = line.rstrip().split(\",\")\r\n",
        "        if image_name not in csv_data:\r\n",
        "          csv_data[image_name] = []\r\n",
        "        csv_data[image_name].append([xmin,ymin,xmax,ymax,label])\r\n",
        "    print(f\"Finished reading data. Images: {len(csv_data.keys())}\")\r\n",
        "\r\n",
        "    # get all the labels and sort them (use a dictionary for O(1) lookup)\r\n",
        "    categories = []\r\n",
        "    for anns in csv_data.values():\r\n",
        "      for ann in anns:\r\n",
        "        label = ann[4]\r\n",
        "        if not label in categories:\r\n",
        "          categories.append(label)\r\n",
        "    categories = sorted(categories)\r\n",
        "    print(f\"First 10 categories are {categories[:10]}\")\r\n",
        "    self.categories = categories\r\n",
        "    categories_map = {label:idx for idx,label in enumerate(categories)}\r\n",
        "    self.categories_map_reverse = {idx:label for idx,label in enumerate(categories)}\r\n",
        "\r\n",
        "    # convert this to the format that detectron2 wants\r\n",
        "    data = []\r\n",
        "    for idx, image_name in enumerate(csv_data.keys()):\r\n",
        "\r\n",
        "      if idx >= 2000: # load more if you want!\r\n",
        "        break\r\n",
        "\r\n",
        "      if idx%100 == 0:\r\n",
        "        print(f\"Processed {idx} images.\")\r\n",
        "      record = {}\r\n",
        "\r\n",
        "      filename = os.path.join(images_dir,image_name)  #str(images_dir/image_name)\r\n",
        "      height, width = cv2.imread(filename).shape[:2]\r\n",
        "      #imageio.imwrite(filename,image_augmentations)\r\n",
        "      \r\n",
        "      record[\"file_name\"] = filename\r\n",
        "      record[\"image_id\"] = idx\r\n",
        "      record[\"height\"] = height\r\n",
        "      record[\"width\"] = width\r\n",
        "\r\n",
        "      annotations = csv_data[image_name]\r\n",
        "      objs = []\r\n",
        "      for annotation in annotations:\r\n",
        "        xmin, ymin, xmax, ymax, label = annotation\r\n",
        "        objs.append({\r\n",
        "            \"bbox\": [float(xmin),float(ymin),float(xmax),float(ymax)],\r\n",
        "            \"bbox_mode\": BoxMode.XYXY_ABS,\r\n",
        "            \"category_id\": categories_map[label]\r\n",
        "        })\r\n",
        "      record[\"annotations\"] = objs\r\n",
        "      data.append(record)\r\n",
        "    \r\n",
        "    self.annotations = data\r\n",
        "\r\n",
        "anns = Annotations()\r\n",
        "anns.compute()\r\n",
        "print(anns.categories_map_reverse)\r\n",
        "print(f\"Finished loading annotations.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDQiSkG-3UTd"
      },
      "source": [
        "# let's register this dataset (unregistered if it exists.)\r\n",
        "def register(name, load_fn, labels):\r\n",
        "  if name in DatasetCatalog.list():\r\n",
        "    DatasetCatalog.remove(name)\r\n",
        "  if name in MetadataCatalog.list():\r\n",
        "    MetadataCatalog.remove(name)\r\n",
        "  \r\n",
        "  DatasetCatalog.register(name, load_fn)\r\n",
        "  MetadataCatalog.get(name).set(thing_classes=labels)\r\n",
        "\r\n",
        "register(\"train\", lambda:anns.annotations, anns.categories)\r\n",
        "#register(\"validation\",lambda:anns_val.annotations, anns_val.categories)\r\n",
        "print(\"Dataset registered.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFX6pwPL3YUP"
      },
      "source": [
        "for d in random.sample(anns.annotations, 1):\r\n",
        "  img = cv2.imread(d[\"file_name\"])\r\n",
        "  visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"train\"), scale=0.5)\r\n",
        "  out = visualizer.draw_dataset_dict(d)\r\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toq-R8Fz3bGH"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "\r\n",
        "cfg = get_cfg()\r\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")) # COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\r\n",
        "#COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\r\n",
        "cfg.DATASETS.TRAIN = (\"train\",)\r\n",
        "cfg.DATASETS.TEST = ()\r\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\r\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo \r\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\r\n",
        "cfg.SOLVER.BASE_LR = 0.00025  \r\n",
        "cfg.SOLVER.MAX_ITER = 9000    \r\n",
        "cfg.SOLVER.STEPS = []      \r\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   \r\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(anns.categories) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXc1Aspz3qOt"
      },
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n",
        "trainer = DefaultTrainer(cfg) \r\n",
        "trainer.resume_or_load(resume=False)\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwLE28D53t8e"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the trained model\r\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FR9a09B3w8E"
      },
      "source": [
        "# visualize inference on some images\r\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0 # if you want to allow predictions with lower accuracy\r\n",
        "predictor = DefaultPredictor(cfg)\r\n",
        "for d in random.sample(DatasetCatalog.get(test_dataset_name), 1):\r\n",
        "  img = cv2.imread(d[\"file_name\"])\r\n",
        "  outputs = predictor(img)\r\n",
        "  visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(test_dataset_name), scale=1)\r\n",
        "  # out = visualizer.draw_dataset_dict(d) # these are the ground truths \r\n",
        "  out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G6HJWpf322g"
      },
      "source": [
        "images_test_dir = 'drive/MyDrive/EdIntelligence-Neurolabs-Hackathon/challenge-2/test/images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXx58zG237p7"
      },
      "source": [
        "outputs = []\r\n",
        "file_names = []\r\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0\r\n",
        "for filename in os.listdir(images_test_dir):\r\n",
        "  image = cv2.imread(os.path.join(images_test_dir,filename))\r\n",
        "  outputs.append(predictor(image))\r\n",
        "  file_names.append(filename)\r\n",
        "print(len(outputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKqiAOyl3-hU"
      },
      "source": [
        "print(file_names)\r\n",
        "print((outputs[0][\"instances\"].pred_classes.cpu().numpy()))\r\n",
        "array = outputs[0][\"instances\"].pred_boxes.tensor.cpu().numpy()\r\n",
        "array = np.array(array,dtype=np.int32)[0]\r\n",
        "print(array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2zkYZ_d4Axc"
      },
      "source": [
        "all_lists = []\r\n",
        "for i in range(len(outputs)):\r\n",
        "  bb_array = outputs[i][\"instances\"].pred_boxes.tensor.cpu().numpy()\r\n",
        "  bb_array = np.array(bb_array,dtype=np.int32)\r\n",
        "  for idx in range(len(outputs[i][\"instances\"].pred_classes.cpu().numpy())):\r\n",
        "    all_lists.append([file_names[i],bb_array[idx][0],bb_array[idx][1],bb_array[idx][2],bb_array[idx][3],outputs[i][\"instances\"].pred_classes.cpu().numpy()[idx]])\r\n",
        "df = pd.DataFrame(all_lists,columns=[\"ImageId\",\"xmin\",\"ymin\",\"xmax\",\"ymax\",\"ClassLabels\"])\r\n",
        "df.head(100)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSTSSVEu4Dnk"
      },
      "source": [
        "df[\"ClassLabels\"] = df[\"ClassLabels\"].apply(lambda x: anns.categories_map_reverse[x] )\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b2UReSJ4GWr"
      },
      "source": [
        "df.to_csv(\"drive/MyDrive/submission-1-challenge-2-faster_rcnn_X_101_32x8d_FPN_3x-no-augment.csv\",header=False,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}